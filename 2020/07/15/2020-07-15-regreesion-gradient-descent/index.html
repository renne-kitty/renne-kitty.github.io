<!DOCTYPE html>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>线性回归-第二阶段 | Renne&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="之前做了一个很简单的线性回归模型，也得到了垃圾一样的结果，这次就尝试优化一下这个结果。">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="线性回归-第二阶段">
<meta property="og:url" content="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/index.html">
<meta property="og:site_name" content="Renne&#39;s Blog">
<meta property="og:description" content="之前做了一个很简单的线性回归模型，也得到了垃圾一样的结果，这次就尝试优化一下这个结果。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/loss-function2.jpg">
<meta property="og:image" content="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/kaggle-2.jpg">
<meta property="og:image" content="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/figure-3.jpg">
<meta property="og:image" content="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/loss-function3.jpg">
<meta property="og:image" content="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/figure-4.jpg">
<meta property="og:updated_time" content="2020-07-23T12:10:16.086Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="线性回归-第二阶段">
<meta name="twitter:description" content="之前做了一个很简单的线性回归模型，也得到了垃圾一样的结果，这次就尝试优化一下这个结果。">
<meta name="twitter:image" content="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/loss-function2.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Renne&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
	<div id="header-touxiang"></div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Renne&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">built on 2019-06-20</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2020-07-15-regreesion-gradient-descent" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/07/15/2020-07-15-regreesion-gradient-descent/" class="article-date">
  <time datetime="2020-07-15T11:36:34.000Z" itemprop="datePublished">2020-07-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      线性回归-第二阶段
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>之前做了一个很简单的线性回归模型，也得到了垃圾一样的结果，这次就尝试优化一下这个结果。</p>
<a id="more"></a>
<h2 id="学习率调整"><a class="markdownIt-Anchor" href="#学习率调整"></a> 学习率调整</h2>
<p>上次的图里面看到了learning rate波动很大，拿去给别人看了一下，一瞬间就判断出学习率有问题，毕竟波动一直没有减少，由开始到最后都这样，因此这里就针对学习率做一些调整。</p>
<p>在上课时，主要先讲了两种自适应学习率的算法：</p>
<h3 id="vanilla-gradient-descent"><a class="markdownIt-Anchor" href="#vanilla-gradient-descent"></a> vanilla gradient descent</h3>
<p>一种比较暴力的办法，对于不少的数据都会有这样的现象，像线性回归这种碗状的模型，我们用梯度下降的时候越往后变化率越低。这个在我们上次的垃圾模型里都可以看到这样的东西，因此有人就弄了一个让学习率随时间下降的函数：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><mfrac><mi>η</mi><msqrt><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\eta_t=\frac{\eta}{\sqrt{t+1}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.03756em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.244445em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8655550000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-2.825555em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17444499999999996em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>我们在我们的代码里面加一下，然后再调调参跑一下，由于它是和时间有关的，所以我将迭代次数增加到原本的10倍，反正放它在那里拼命跑就行了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">iteration_count = <span class="number">100000</span></span><br><span class="line">paras_num = len(x_train[<span class="number">0</span>])</span><br><span class="line">parameters = [<span class="number">0.001</span>] * paras_num</span><br><span class="line">b = <span class="number">0.000</span></span><br><span class="line">learning_rate_eta = <span class="number">0.000005</span></span><br><span class="line">loss_history = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(iteration_count):</span><br><span class="line">    sample_per_learn = <span class="number">100</span></span><br><span class="line">    examples = list(np.random.randint(<span class="number">0</span>,len(x_train)<span class="number">-1</span>) <span class="keyword">for</span> index <span class="keyword">in</span> range(sample_per_learn))</span><br><span class="line">    w_grad = [<span class="number">0.0</span>] * paras_num</span><br><span class="line">    b_grad = <span class="number">0</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(sample_per_learn):</span><br><span class="line">        sample_index = examples.pop()</span><br><span class="line">        day = x_train[sample_index]</span><br><span class="line"></span><br><span class="line">        bias = b - float(y_train[sample_index])</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">            bias += float(day[k]) * parameters[k]</span><br><span class="line">        b_grad += bias</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">            w_grad[k] += bias * float(day[k])</span><br><span class="line">        loss += bias * bias</span><br><span class="line"></span><br><span class="line">    loss /= (<span class="number">2</span>*sample_per_learn)</span><br><span class="line">    b_grad /= sample_per_learn</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        w_grad[k] /= sample_per_learn</span><br><span class="line"></span><br><span class="line">    loss_history.append(loss)</span><br><span class="line">    learning_rate = learning_rate_eta / np.sqrt(i+<span class="number">1</span>) <span class="comment"># eta / sqrt(t+1)</span></span><br><span class="line">    b -= learning_rate * b_grad</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        parameters[k] -= learning_rate * w_grad[k]</span><br></pre></td></tr></table></figure>
<p>跑出来的结果好像还是一般般。。</p>
<p><img src="loss-function2.jpg" alt="loss-function-vanilla"></p>
<p>放Kaggle跑一下，kaggle要等待时间挺长的。想不到，虽然在图上看还是这么垃圾，但放上面跑却好了一点点，虽然还是这么垃圾。</p>
<p><img src="kaggle-2.jpg" alt="kaggle-vanilla-gradient-descent"></p>
<p>----- simple baseline ----- 8.73773离合格都还有点距离</p>
<p>继续努力学下种优化方法吧</p>
<h3 id="adagrad"><a class="markdownIt-Anchor" href="#adagrad"></a> adagrad</h3>
<p>上面的算法虽然提升了我们一点点分数，但明显能看到，它的失败是因为学习率还是没有降下去，如果一下子就将t变大，有可能又会使它在开始降太慢。那接下来我们学的adagrad根据之前的样本调整学习率的算法</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mi>i</mi></msub><mo>−</mo><mfrac><msub><mi>η</mi><mi>t</mi></msub><msub><mi>σ</mi><mi>t</mi></msub></mfrac><msub><mi>g</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><mfrac><mi>η</mi><msqrt><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msqrt></mfrac><mo separator="true">,</mo><msub><mi>σ</mi><mi>t</mi></msub><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>t</mi></munderover><msubsup><mi>g</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">w_{i+1}=w_i-\frac{\eta_t}{\sigma_t}g_t,\eta_t=\frac{\eta}{\sqrt{t+1}},\sigma_t=\sqrt{\frac{1}{t+1}\sum^t_{i=0}g_i^2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.94356em;vertical-align:-0.8360000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.03756em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.244445em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8655550000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-2.825555em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17444499999999996em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.28598em;vertical-align:-1.277669em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.008311em;"><span class="svg-align" style="top:-5.245979999999999em;"><span class="pstrut" style="height:5.245979999999999em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7805610000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959080000000001em;"><span style="top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27686399999999994em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.9683109999999995em;"><span class="pstrut" style="height:5.245979999999999em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.32598em;"><svg width="400em" height="3.32598em" viewbox="0 0 400000 3325" preserveaspectratio="xMinYMin slice"><path d="M702 80H400000v40H742v3191l-4 4-4 4c-.667.7
-2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667
-294.333-240-727l-212 -643 -85 170c-4-3.333-8.333-7.667-13 -13l-13-13l77-155
 77-156c66 199.333 139 419.667 219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>这里的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">g_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>指的是上次说过的偏微分，它在随时间的基础上加上了方差的变化。继续化简一下上面的式子吧</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mi>i</mi></msub><mo>−</mo><mfrac><mi>η</mi><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>t</mi></munderover><msubsup><mi>g</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mfrac><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_{i+1}=w_i-\frac{\eta}{\sqrt{\sum^t_{i=0}g_i^2}}g_t
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.83756em;vertical-align:-1.73em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.301873em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.301873em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.933456em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959080000000001em;"><span style="top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.27686399999999994em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.261873em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width="400em" height="1.8800000000000001em" viewbox="0 0 400000 1944" preserveaspectratio="xMinYMin slice"><path d="M1001,80H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,
572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,
-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39
c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60
s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,
-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5c4,-6.7,10,-10,18,-10z
M1001 80H400000v40H1013z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5381269999999999em;"><span></span></span></span></span></span></span></span><span style="top:-3.531873em;"><span class="pstrut" style="height:3.301873em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.978873em;"><span class="pstrut" style="height:3.301873em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.73em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>我们也实现一下吧，对于每个不同的参数都要做不同处理，毕竟他们的g都是不一样的。这时其实顺便解决了b的初始化问题，因为后来看到其实b是到最后都没有收敛的，我改了一下b的初始值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">iteration_count = <span class="number">100000</span></span><br><span class="line">paras_num = len(x_train[<span class="number">0</span>])</span><br><span class="line">parameters = [<span class="number">0.001</span>] * paras_num</span><br><span class="line">b = <span class="number">1.3</span></span><br><span class="line">learning_rate_eta = <span class="number">0.01</span></span><br><span class="line">loss_history = []</span><br><span class="line">b_history = []</span><br><span class="line">w0_history = []</span><br><span class="line">w20_history = []</span><br><span class="line"></span><br><span class="line">gw_square_sum = [<span class="number">0.0</span>] * paras_num</span><br><span class="line">gb_square_sum = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(iteration_count):</span><br><span class="line">    sample_per_learn = <span class="number">100</span></span><br><span class="line">    examples = list(np.random.randint(<span class="number">0</span>,len(x_train)<span class="number">-1</span>) <span class="keyword">for</span> index <span class="keyword">in</span> range(sample_per_learn))</span><br><span class="line">    w_grad = [<span class="number">0.0</span>] * paras_num</span><br><span class="line">    b_grad = <span class="number">0</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(sample_per_learn):</span><br><span class="line">        sample_index = examples.pop()</span><br><span class="line">        day = x_train[sample_index]</span><br><span class="line"></span><br><span class="line">        bias = b - float(y_train[sample_index])<span class="comment"># sum(wixi+b-y)</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">            bias += float(day[k]) * parameters[k]</span><br><span class="line">        b_grad += bias</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">            w_grad[k] += bias * float(day[k])</span><br><span class="line">        loss += bias * bias</span><br><span class="line"></span><br><span class="line">    loss /= (<span class="number">2</span>*sample_per_learn)</span><br><span class="line">    b_grad /= sample_per_learn</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        w_grad[k] /= sample_per_learn</span><br><span class="line"></span><br><span class="line">    gb_square_sum += b_grad*b_grad</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        gw_square_sum[k] += w_grad[k]*w_grad[k]</span><br><span class="line"></span><br><span class="line">    loss_history.append(loss)</span><br><span class="line"><span class="comment">#    learning_rate = learning_rate_eta / np.sqrt(i+1)</span></span><br><span class="line">    b -= learning_rate_eta / np.sqrt(gb_square_sum) * b_grad</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        parameters[k] -= learning_rate_eta / np.sqrt(gw_square_sum[k]) * w_grad[k]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出一下b的历史看看</span></span><br><span class="line">    b_history.append(b)</span><br><span class="line">    w0_history.append(parameters[<span class="number">0</span>])</span><br><span class="line">    w20_history.append(parameters[<span class="number">20</span>])</span><br></pre></td></tr></table></figure>
<p>从数据上来看是还没有收敛的，像b和w都还有上涨的空间</p>
<p><img src="figure-3.jpg" alt="figure"></p>
<p>但想不到提交上kaggle还挺不错的，想不到private数据集直接就过了strong base line，虽然完全可以说是凭运气过的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submission details 7.12969 5.83429</span><br></pre></td></tr></table></figure>
<h2 id="数据归一化"><a class="markdownIt-Anchor" href="#数据归一化"></a> 数据归一化</h2>
<p>其实这点一直是漏了的，对于所有类型的数据，我们都应该先做一个归一化处理，然后才是剩下的工作。比如说现在的数据，我们看PM2.5的数据，都是18-43左右的；但看二氧化硫的数据，都是很小带一位小数的。如果用上面相同的方式去处理，也许数据出来的范围会有点问题，毕竟我们求Loss function导致的变化率变动是全局影响的。</p>
<p>在概率论里面我们也学过一种通过正太分布归一化的方式，令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow></msub><mo>=</mo><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac></mrow><annotation encoding="application/x-tex">x_{project} = \frac{x_i-\mu}{\sigma}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.199439em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.854439em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，也就是把他们映射到一个正态分布上。之后的测试数据的输入也是按照这样的方式归一化，输出反过来先乘上标准差再加上均值就可以了。</p>
<p>对于这里的数据，我们也是做这样的处理。首先得将二氧化硫、PM10、PM2.5都分开处理。下面是完整的代码，还没提交不知道分数怎么样，直接开了个50w次让它跑个半小时吧。</p>
<p>但实际Kaggle的数据表示这样的归一化的效果很一般。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submission 7.26403 5.72854</span><br></pre></td></tr></table></figure>
<h2 id="为什么loss这么大"><a class="markdownIt-Anchor" href="#为什么loss这么大"></a> 为什么loss这么大</h2>
<p>很简单，因为代码是抄来的。。我们使用了随机的学习样本，原本是随机选取100个作为输入，每100个数据都会有它不同的特征。如果我们把样本换成固定的样本，那loss function会变成一条比较平滑的线，其实李宏毅在上课时讲的做法应该时这种才对吧。然后我就改了几行代码试了一试。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sample_per_learn = len(x_train)</span><br><span class="line">examples = [k <span class="keyword">for</span> k <span class="keyword">in</span> range(len(x_train))]</span><br></pre></td></tr></table></figure>
<p>得到的图像比以前的好看多了，只不过现在的状况看到loss function貌似还没收敛，也许加大迭代次数或者学习率还有上涨的空间。但是这样做效率是很低的，原本还能迭代个500000次，现在迭代个10000次都不知道要跑多久了。虽然实际的优化效果也是很一般，也许和过拟合有关，之后就再在里面。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submission 7.28442 5.72602</span><br></pre></td></tr></table></figure>
<p><img src="loss-function3.jpg" alt="loss-function-3"></p>
<h2 id="其它的一些尝试"><a class="markdownIt-Anchor" href="#其它的一些尝试"></a> 其它的一些尝试</h2>
<p>之前试过把所有类别的数据都给加进来。但实际证明，如果样本选择是随机的，给样本更多的变量会降低最终的结果，因为当样本变大时，如果选取相同的随机数量，那随机性也会变大。这种随机性只是有利于提高性能，但对提高准确度没好处。如果把样本所有变量放进来会使弱点进一步被放大。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submission 25.63060 16.41304</span><br></pre></td></tr></table></figure>
<p>之后在把全部样本放进来的情况作个死，把全部的变量都给放进来，结果100的迭代次数都已经跑了很久。但结果是非常糟糕的，也许把别的无关因素给引了进来。</p>
<p>然后弄过一下正则化，就是在方程里加入参数项，然后在loss里面加点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>w</mi><mi>i</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">w_i^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.072772em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.441336em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span>这样的东西。但表现效果不是很好，还降低了分数，本来都还有5分的直接就变成6分多了。应该是因为训练的数据量还是非常小，而且模型很简单，一阶的线性的线性回归方式都很难做到过拟合</p>
<h2 id="最终代码"><a class="markdownIt-Anchor" href="#最终代码"></a> 最终代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># kaggle 结果 private=7.28447 public=5.72584</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="string">'''归一化输入样例'''</span></span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(<span class="string">"train.csv"</span>, encoding=<span class="string">'ISO-8859-1'</span>)</span><br><span class="line">train_data.drop([<span class="string">'date'</span>, <span class="string">'place'</span>, <span class="string">'type'</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_data.replace(<span class="string">"NR"</span>,<span class="number">0.0</span>,<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ItemNum = <span class="number">18</span></span><br><span class="line"></span><br><span class="line">rowUse = [<span class="number">8</span>,<span class="number">9</span>,<span class="number">12</span>]</span><br><span class="line"><span class="comment">#rowUse = [i for i in range(ItemNum)]</span></span><br><span class="line"></span><br><span class="line">x_train_data = [[] <span class="keyword">for</span> index <span class="keyword">in</span> rowUse]</span><br><span class="line">x_mean = []</span><br><span class="line">x_std = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(int(len(train_data)/ItemNum)):</span><br><span class="line">    daily_data = train_data.iloc[i*ItemNum:(i+<span class="number">1</span>)*ItemNum]</span><br><span class="line">    <span class="keyword">for</span> index, rowIndex <span class="keyword">in</span> enumerate(rowUse):</span><br><span class="line">        x_single_tab = daily_data.iloc[rowIndex, :]</span><br><span class="line">        <span class="keyword">for</span> x_val <span class="keyword">in</span> x_single_tab:</span><br><span class="line">            x_train_data[index].append(float(x_val))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standard</span><span class="params">(val, mean, std)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (val-mean)/std</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">re_standard</span><span class="params">(val)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> val * <span class="number">16.661090903986995</span> + <span class="number">21.414236111111112</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x_single_tab <span class="keyword">in</span> x_train_data:</span><br><span class="line">    mean = np.mean(x_single_tab)</span><br><span class="line">    std = np.std(x_single_tab)</span><br><span class="line">    x_mean.append(mean)</span><br><span class="line">    x_std.append(std)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x_single_tab)):</span><br><span class="line">        x_single_tab[i] = standard(x_single_tab[i],mean,std)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_train = []</span><br><span class="line">y_train = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(x_train_data[<span class="number">0</span>])<span class="number">-10</span>):</span><br><span class="line">    x_daily_sample = []</span><br><span class="line">    <span class="keyword">for</span> index, j <span class="keyword">in</span> enumerate(rowUse):</span><br><span class="line">        <span class="keyword">for</span> val <span class="keyword">in</span> x_train_data[index][i:i+<span class="number">9</span>]:</span><br><span class="line">            x_daily_sample.append(val)</span><br><span class="line">    x_train.append(x_daily_sample)</span><br><span class="line">    y_train.append(x_train_data[<span class="number">1</span>][i+<span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iteration_count = <span class="number">2000</span></span><br><span class="line">paras_num = len(x_train[<span class="number">0</span>])</span><br><span class="line">parameters = [<span class="number">0.0</span>] * paras_num</span><br><span class="line">b = <span class="number">0.0</span></span><br><span class="line">learning_rate_eta = <span class="number">0.1</span></span><br><span class="line">loss_history = []</span><br><span class="line">b_history = []</span><br><span class="line">w0_history = []</span><br><span class="line">w20_history = []</span><br><span class="line"></span><br><span class="line">gw_square_sum = [<span class="number">0.0</span>] * paras_num</span><br><span class="line">gb_square_sum = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(iteration_count):</span><br><span class="line">    <span class="comment"># sample_per_learn = 1000</span></span><br><span class="line">    <span class="comment"># examples = list(np.random.randint(0,len(x_train)-1) for index in range(sample_per_learn))</span></span><br><span class="line">    sample_per_learn = len(x_train)</span><br><span class="line">    examples = [k <span class="keyword">for</span> k <span class="keyword">in</span> range(len(x_train))]</span><br><span class="line">    w_grad = [<span class="number">0.0</span>] * paras_num</span><br><span class="line">    b_grad = <span class="number">0</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(sample_per_learn):</span><br><span class="line">        sample_index = examples.pop()</span><br><span class="line">        day = x_train[sample_index]</span><br><span class="line"></span><br><span class="line">        bias = b - float(y_train[sample_index])<span class="comment"># sum(wixi+b-y)</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">            bias += float(day[k]) * parameters[k]</span><br><span class="line">        b_grad += bias</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">            w_grad[k] += bias * float(day[k])</span><br><span class="line"></span><br><span class="line">        loss += bias * bias</span><br><span class="line"></span><br><span class="line">    loss /= (<span class="number">2</span>*sample_per_learn)</span><br><span class="line">    b_grad /= sample_per_learn</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        w_grad[k] /= sample_per_learn</span><br><span class="line"></span><br><span class="line">    gb_square_sum += b_grad*b_grad</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        gw_square_sum[k] += w_grad[k]*w_grad[k]</span><br><span class="line"></span><br><span class="line">    loss_history.append(loss)</span><br><span class="line"><span class="comment">#    learning_rate = learning_rate_eta / np.sqrt(i+1)</span></span><br><span class="line">    b -= learning_rate_eta / np.sqrt(gb_square_sum) * b_grad</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        parameters[k] -= learning_rate_eta / np.sqrt(gw_square_sum[k]) * w_grad[k]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出一下b的历史看看</span></span><br><span class="line">    b_history.append(b)</span><br><span class="line">    w0_history.append(parameters[<span class="number">0</span>])</span><br><span class="line">    w20_history.append(parameters[<span class="number">20</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"loss function"</span>)</span><br><span class="line">plt.plot(loss_history)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"w0"</span>)</span><br><span class="line">plt.plot(w0_history)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">"w20"</span>)</span><br><span class="line">plt.plot(w20_history)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.title(<span class="string">"b"</span>)</span><br><span class="line">plt.plot(b_history)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="string">'''输出结果'''</span></span><br><span class="line">data_test = pd.read_csv(<span class="string">"test.csv"</span>)</span><br><span class="line">data_test.drop([<span class="string">"id"</span>,<span class="string">"type"</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">data_test.replace(<span class="string">"NR"</span>,<span class="number">0.0</span>,<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">data_output = &#123;&#125;</span><br><span class="line"></span><br><span class="line">ItemNum = <span class="number">18</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(int(len(data_test)/ItemNum)):</span><br><span class="line">    id_data = data_test.iloc[i*ItemNum:(i+<span class="number">1</span>)*ItemNum]</span><br><span class="line">    x_list_array = id_data.values.tolist()</span><br><span class="line">    x_list = []</span><br><span class="line">    <span class="keyword">for</span> index, x_row_index <span class="keyword">in</span> enumerate(rowUse):</span><br><span class="line">        <span class="keyword">for</span> x_val <span class="keyword">in</span> x_list_array[x_row_index]:</span><br><span class="line">            x_list.append(standard(float(x_val), x_mean[index], x_std[index]))</span><br><span class="line">    predict_val = b</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(paras_num):</span><br><span class="line">        predict_val += parameters[k] * float(x_list[k])</span><br><span class="line"></span><br><span class="line">    row_index = <span class="string">"id_"</span> + str(i)</span><br><span class="line">    data_output[row_index] = re_standard(predict_val)</span><br><span class="line"></span><br><span class="line">df = pd.Series(data_output)</span><br><span class="line">df.to_csv(<span class="string">"formal_submission.csv"</span>)</span><br></pre></td></tr></table></figure>
<p>loss function:</p>
<p><img src="figure-4.jpg" alt="figure-4"></p>
<p>p.s. 折腾了一整天的线性回归，玩够了，以后再玩吧。。</p>
<h2 id="反思"><a class="markdownIt-Anchor" href="#反思"></a> 反思</h2>
<p>代码真的太烂了，之后看了一下逻辑回归别人写的代码，也许可以将代码提速不知道多少倍。。也许差不多五六倍吧，几乎相同的逻辑，直接用矩阵，都不用GPU了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/07/15/2020-07-15-regreesion-gradient-descent/" data-id="ckdrhhcjy0096rwtmyxllinkx" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/07/15/2020-07-15-classification-base/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          分类问题作业-课程内容整理
        
      </div>
    </a>
  
  
    <a href="/2020/07/14/2020-07-14-codeforces-edu88/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">codeforces edu 88</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/xargs/">xargs</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/刷题记录/">刷题记录</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/区块链/">区块链</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/密码学/">密码学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/根域名/">根域名</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DHT/">DHT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DNS/">DNS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/acm/">acm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/android/">android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/arch/">arch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blockstack/">blockstack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/codeforces/">codeforces</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ctf/">ctf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fabric/">fabric</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/">go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/namecoin/">namecoin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node-js/">node.js</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ssh/">ssh</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zookeeper/">zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/以太坊/">以太坊</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/刷题/">刷题</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/区块链/">区块链</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/实验/">实验</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/密码学/">密码学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数学/">数学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/智能合约/">智能合约</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/根域名/">根域名</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/概率论/">概率论</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/比特币/">比特币</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/源码/">源码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/漏洞/">漏洞</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编程语言/">编程语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/联盟链/">联盟链</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/虚拟机/">虚拟机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/超级账本/">超级账本</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/DHT/" style="font-size: 10px;">DHT</a> <a href="/tags/DNS/" style="font-size: 16px;">DNS</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/acm/" style="font-size: 10px;">acm</a> <a href="/tags/android/" style="font-size: 10px;">android</a> <a href="/tags/arch/" style="font-size: 14px;">arch</a> <a href="/tags/blockstack/" style="font-size: 13px;">blockstack</a> <a href="/tags/codeforces/" style="font-size: 10px;">codeforces</a> <a href="/tags/ctf/" style="font-size: 10px;">ctf</a> <a href="/tags/docker/" style="font-size: 12px;">docker</a> <a href="/tags/fabric/" style="font-size: 13px;">fabric</a> <a href="/tags/github/" style="font-size: 12px;">github</a> <a href="/tags/go/" style="font-size: 11px;">go</a> <a href="/tags/leetcode/" style="font-size: 11px;">leetcode</a> <a href="/tags/linux/" style="font-size: 19px;">linux</a> <a href="/tags/namecoin/" style="font-size: 13px;">namecoin</a> <a href="/tags/node-js/" style="font-size: 12px;">node.js</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/ssh/" style="font-size: 11px;">ssh</a> <a href="/tags/zookeeper/" style="font-size: 10px;">zookeeper</a> <a href="/tags/以太坊/" style="font-size: 17px;">以太坊</a> <a href="/tags/刷题/" style="font-size: 13px;">刷题</a> <a href="/tags/区块链/" style="font-size: 20px;">区块链</a> <a href="/tags/大数据/" style="font-size: 11px;">大数据</a> <a href="/tags/实验/" style="font-size: 13px;">实验</a> <a href="/tags/密码学/" style="font-size: 13px;">密码学</a> <a href="/tags/数学/" style="font-size: 13px;">数学</a> <a href="/tags/智能合约/" style="font-size: 12px;">智能合约</a> <a href="/tags/机器学习/" style="font-size: 18px;">机器学习</a> <a href="/tags/根域名/" style="font-size: 15px;">根域名</a> <a href="/tags/概率论/" style="font-size: 11px;">概率论</a> <a href="/tags/比特币/" style="font-size: 12px;">比特币</a> <a href="/tags/深度学习/" style="font-size: 13px;">深度学习</a> <a href="/tags/源码/" style="font-size: 11px;">源码</a> <a href="/tags/漏洞/" style="font-size: 10px;">漏洞</a> <a href="/tags/算法/" style="font-size: 14px;">算法</a> <a href="/tags/编程语言/" style="font-size: 11px;">编程语言</a> <a href="/tags/联盟链/" style="font-size: 13px;">联盟链</a> <a href="/tags/虚拟机/" style="font-size: 10px;">虚拟机</a> <a href="/tags/超级账本/" style="font-size: 11px;">超级账本</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/08/12/2020-08-12-seq2seq-auto-encoder/">RNN-seq2seq</a>
          </li>
        
          <li>
            <a href="/2020/08/11/2020-08-12-xargs/">xargs命令使用例子</a>
          </li>
        
          <li>
            <a href="/2020/08/05/2020-08-05-fabric-network-in-script/">利用测试网络的脚本搭建超级账本2.0网络</a>
          </li>
        
          <li>
            <a href="/2020/07/23/2020-07-23-git-multi-accounts/">git多账号管理</a>
          </li>
        
          <li>
            <a href="/2020/07/23/2020-07-23-rnn-lstm/">RNN-lstm介绍</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Renne<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>