<!DOCTYPE html>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>分类问题作业-2 | Renne&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="提交地址：https://www.kaggle.com/c/ml2020spring-hw2 作业范例：https://colab.research.google.com/drive1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C#scrollTo=DH3AJtvHjVJ7">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="分类问题作业-2">
<meta property="og:url" content="http://yoursite.com/2020/07/16/2020-07-16-classification-hw2/index.html">
<meta property="og:site_name" content="Renne&#39;s Blog">
<meta property="og:description" content="提交地址：https://www.kaggle.com/c/ml2020spring-hw2 作业范例：https://colab.research.google.com/drive1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C#scrollTo=DH3AJtvHjVJ7">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-07-23T12:10:10.757Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分类问题作业-2">
<meta name="twitter:description" content="提交地址：https://www.kaggle.com/c/ml2020spring-hw2 作业范例：https://colab.research.google.com/drive1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C#scrollTo=DH3AJtvHjVJ7">
  
    <link rel="alternate" href="/atom.xml" title="Renne&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
	<div id="header-touxiang"></div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Renne&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">built on 2019-06-20</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2020-07-16-classification-hw2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/07/16/2020-07-16-classification-hw2/" class="article-date">
  <time datetime="2020-07-16T11:41:37.000Z" itemprop="datePublished">2020-07-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      分类问题作业-2
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>提交地址：<a href="https://www.kaggle.com/c/ml2020spring-hw2" target="_blank" rel="noopener">https://www.kaggle.com/c/ml2020spring-hw2</a></p>
<p>作业范例：<a href="https://colab.research.google.com/drive1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C#scrollTo=DH3AJtvHjVJ7" target="_blank" rel="noopener">https://colab.research.google.com/drive1JaMKJU7hvnDoUfZjvUKzm9u-JLeX6B2C#scrollTo=DH3AJtvHjVJ7</a></p>
<a id="more"></a>
<h2 id="修改范例的结果"><a class="markdownIt-Anchor" href="#修改范例的结果"></a> 修改范例的结果</h2>
<p>上次直接手打了一个gradient descent，代码真的太难看了，所以这次就干脆先看看别人是怎么写Py的。结果还真发现一换人，就完全不同了，这写法至少比我自己那种for,for,for要好看多了，而且用矩阵来运算也可以通过多核或者gpu提升速度。抄代码还真学了不少。</p>
<p>我从代码里改了一点点参数，直接把训练样例调到了99%，测试样例调成1%。然后单batch为20笔数据，迭代2500次。而且，我把样本随机给关掉了，直接按顺序跑所有数据，20*2500刚好能跑完50000个数据。</p>
<p>在kaggle上跑分0.89117，在private里面刚好超过strong base line。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">x_train_fpath = <span class="string">"./data/X_train"</span></span><br><span class="line">y_train_fpath = <span class="string">"./data/Y_train"</span></span><br><span class="line">x_test_fpath = <span class="string">"./data/X_test"</span></span><br><span class="line">y_test_output = <span class="string">"./data/output.csv"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(x_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float)</span><br><span class="line"><span class="keyword">with</span> open(y_train_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    Y_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">2</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float)</span><br><span class="line"><span class="keyword">with</span> open(x_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_test = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f], dtype=float)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_normalize</span><span class="params">(X, train=True, specified_column=None, x_mean=None, x_std=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> specified_column == <span class="literal">None</span>:</span><br><span class="line">        specified_column = np.arange(X.shape[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        x_mean = np.mean(X[:, specified_column], <span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        x_std = np.std(X[:, specified_column],<span class="number">0</span>).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">    X[:, specified_column] = (X[:, specified_column] - x_mean) / (x_std + <span class="number">1e-8</span>)</span><br><span class="line">    <span class="keyword">return</span> X, x_mean, x_std</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_train_dev_split</span><span class="params">(X, Y, dev_ratio = <span class="number">0.25</span>)</span>:</span></span><br><span class="line">    train_size = int(len(X) * (<span class="number">1</span>-dev_ratio))</span><br><span class="line">    <span class="keyword">return</span> X[:train_size], Y[:train_size], X[train_size:], Y[train_size:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train, X_mean, X_std = _normalize(X_train, train=<span class="literal">True</span>)</span><br><span class="line">X_test, _, _ = _normalize(X_test, train=<span class="literal">False</span>,specified_column=<span class="literal">None</span>,x_mean=X_mean,x_std= X_std)</span><br><span class="line"></span><br><span class="line"><span class="comment"># split</span></span><br><span class="line">dev_ratio = <span class="number">0.01</span></span><br><span class="line">X_train, Y_train, X_dev,Y_dev = _train_dev_split(X_train, Y_train, dev_ratio)</span><br><span class="line"></span><br><span class="line">train_size = X_train.shape[<span class="number">0</span>]</span><br><span class="line">dev_size = X_dev.shape[<span class="number">0</span>]</span><br><span class="line">test_size = X_test.shape[<span class="number">0</span>]</span><br><span class="line">data_dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line">print(<span class="string">'Size of training set: &#123;&#125;'</span>.format(train_size))</span><br><span class="line">print(<span class="string">'Size of development set: &#123;&#125;'</span>.format(dev_size))</span><br><span class="line">print(<span class="string">'Size of testing set: &#123;&#125;'</span>.format(test_size))</span><br><span class="line">print(<span class="string">'Dimension of data: &#123;&#125;'</span>.format(data_dim))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_shuffle</span><span class="params">(X, Y)</span>:</span></span><br><span class="line">    randomize = np.arange(len(X))</span><br><span class="line">    np.random.shuffle(randomize)</span><br><span class="line">    <span class="keyword">return</span> X[randomize], Y[randomize]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.clip(<span class="number">1</span> / (<span class="number">1.0</span>+np.exp(-z)), <span class="number">1e-8</span>, <span class="number">1</span> - <span class="number">1e-8</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_f</span><span class="params">(X, w, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> _sigmoid(np.matmul(X, w) + b)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_predict</span><span class="params">(X, w, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.round(_f(X, w, b)).astype(np.int)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_accuracy</span><span class="params">(Y_pred, Y_label)</span>:</span></span><br><span class="line">    acc = <span class="number">1</span> - np.mean(np.abs(Y_pred - Y_label))</span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_cross_entropy_loss</span><span class="params">(y_pred, Y_label)</span>:</span></span><br><span class="line">    cross_entropy = -np.dot(Y_label, np.log(y_pred)) - np.dot((<span class="number">1</span> - Y_label),np.log(<span class="number">1</span> - y_pred))</span><br><span class="line">    <span class="keyword">return</span> cross_entropy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gradient</span><span class="params">(X, Y_label, w, b)</span>:</span></span><br><span class="line">    <span class="comment"># This function computes the gradient of cross entropy loss with respect to weight w and bias b.</span></span><br><span class="line">    y_pred = _f(X, w, b)</span><br><span class="line">    pred_error = Y_label - y_pred</span><br><span class="line">    w_grad = -np.sum(pred_error * X.T, <span class="number">1</span>)</span><br><span class="line">    b_grad = -np.sum(pred_error)</span><br><span class="line">    <span class="keyword">return</span> w_grad, b_grad</span><br><span class="line"></span><br><span class="line">w = np.zeros((data_dim,))</span><br><span class="line">b = np.zeros((<span class="number">1</span>,))</span><br><span class="line"></span><br><span class="line">max_iter = <span class="number">2500</span></span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">train_loss = []</span><br><span class="line">dev_loss = []</span><br><span class="line">train_acc = []</span><br><span class="line">dev_acc = []</span><br><span class="line"></span><br><span class="line">step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(max_iter):</span><br><span class="line"><span class="comment">#    X_train, Y_train = _shuffle(X_train, Y_train)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(int(np.floor(train_size / batch_size))):</span><br><span class="line">        X = X_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line">        Y = Y_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line"></span><br><span class="line">        w_grad, b_grad = _gradient(X, Y, w, b)</span><br><span class="line"></span><br><span class="line">        w = w - learning_rate/np.sqrt(step) * w_grad</span><br><span class="line">        b = b - learning_rate/np.sqrt(step) * b_grad</span><br><span class="line"></span><br><span class="line">        step = step + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    y_train_pred = _f(X_train, w, b)</span><br><span class="line">    Y_train_pred = np.round(y_train_pred)</span><br><span class="line">    train_acc.append(_accuracy(Y_train_pred,Y_train))</span><br><span class="line">    train_loss.append(_cross_entropy_loss(y_train_pred, Y_train)/train_size)</span><br><span class="line"></span><br><span class="line">    y_dev_pred = _f(X_dev, w, b)</span><br><span class="line">    Y_dev_pred = np.round(y_dev_pred)</span><br><span class="line">    dev_acc.append(_accuracy(Y_dev_pred,Y_dev))</span><br><span class="line">    dev_loss.append(_cross_entropy_loss(y_dev_pred, Y_dev)/ dev_size)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Training loss: &#123;&#125;'</span>.format(train_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Development loss: &#123;&#125;'</span>.format(dev_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Training accuracy: &#123;&#125;'</span>.format(train_acc[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Development accuracy: &#123;&#125;'</span>.format(dev_acc[<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss curve</span></span><br><span class="line">plt.plot(train_loss)</span><br><span class="line">plt.plot(dev_loss)</span><br><span class="line">plt.title(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'dev'</span>])</span><br><span class="line">plt.savefig(<span class="string">'loss.png'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy curve</span></span><br><span class="line">plt.plot(train_acc)</span><br><span class="line">plt.plot(dev_acc)</span><br><span class="line">plt.title(<span class="string">'Accuracy'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>, <span class="string">'dev'</span>])</span><br><span class="line">plt.savefig(<span class="string">'acc.png'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">prediction = _predict(X_test, w, b)</span><br><span class="line"><span class="keyword">with</span> open(y_test_output.format(<span class="string">'logistic'</span>), <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">'id,label\n'</span>)</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(prediction):</span><br><span class="line">        f.write(<span class="string">'&#123;&#125;,&#123;&#125;\n'</span>.format(i,label))</span><br><span class="line"></span><br><span class="line">ind = np.argsort(np.abs(w))[::<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">with</span> open(x_test_fpath) <span class="keyword">as</span> f:</span><br><span class="line">    content = f.readline().strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)</span><br><span class="line">features = np.array(content)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ind[<span class="number">0</span>:<span class="number">10</span>]:</span><br><span class="line">    print(features[i], w[i])</span><br></pre></td></tr></table></figure>
<h2 id="画瓢"><a class="markdownIt-Anchor" href="#画瓢"></a> 画瓢</h2>
<p>画面上的代码太美丽的，不是我写得出来的，毕竟第一次接触numpy这个库，原来对数据处理这么方便。于是干脆就自己也照着写一个，分析一下代码，顺便熟悉一下numpy。</p>
<h3 id="数据读入"><a class="markdownIt-Anchor" href="#数据读入"></a> 数据读入</h3>
<p>数据读入没有采取之前用pandas库的方式，直接用了numpy的数据结构来弄，直接把csv的格式给拆了，毕竟就是这样比较简单的格式才比较好拆。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train_file = <span class="string">"./data/X_train"</span></span><br><span class="line">y_train_file = <span class="string">"./data/Y_train"</span></span><br><span class="line">x_test_file = <span class="string">"./data/X_test"</span></span><br><span class="line">x_test_output = <span class="string">"./data/output.csv"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(x_train_file) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f],dtype=float)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(y_train_file) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    Y_train = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f],dtype=float)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(x_test_file) <span class="keyword">as</span> f:</span><br><span class="line">    next(f)</span><br><span class="line">    X_test = np.array([line.strip(<span class="string">'\n'</span>).split(<span class="string">','</span>)[<span class="number">1</span>:] <span class="keyword">for</span> line <span class="keyword">in</span> f],dtype=float)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"x_train shape = "</span>,X_train.shape)</span><br><span class="line">print(<span class="string">"y_train shape = "</span>,Y_train.shape)</span><br><span class="line">print(<span class="string">"x_test shape = "</span>,X_test.shape)</span><br></pre></td></tr></table></figure>
<h3 id="生成样例"><a class="markdownIt-Anchor" href="#生成样例"></a> 生成样例</h3>
<h4 id="分割数据集"><a class="markdownIt-Anchor" href="#分割数据集"></a> 分割数据集</h4>
<p>首先把数据集顺序给打乱，使他每次都出不同的，但又符合逻辑的结果。</p>
<p>将训练数据分为两部分，一部分是用于测试，另一部分用于本地校验。毕竟要是本地的校验正确率都太低，那都没有提交到kaggle的必要了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle</span><span class="params">(X, Y)</span>:</span></span><br><span class="line">    new_index_group = np.arange(len(X))</span><br><span class="line">    np.random.shuffle(new_index_group)</span><br><span class="line">    <span class="keyword">return</span> x[new_index_group],Y[new_index_group]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_train_dev</span><span class="params">(X_train, Y_train, dev_ratio=<span class="number">0.25</span>)</span>:</span></span><br><span class="line">    train_size = int(len(X_train) * (<span class="number">1</span> - dev_ratio - <span class="number">1e-8</span>))</span><br><span class="line">    <span class="keyword">return</span> X_train[:train_size],Y_train[:train_size], X_train[train_size:],Y_train[:train_size]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">shuffle(X_train,Y_train)</span><br><span class="line">X_train, Y_train, X_dev, Y_dev = split_train_dev(X_train,Y_train)</span><br></pre></td></tr></table></figure>
<h4 id="归一化"><a class="markdownIt-Anchor" href="#归一化"></a> 归一化</h4>
<p>归一化的方法与之前写线性回归时一样，都是假定为正态分布，取均值和方差。只不过直接用矩阵来弄，比我之前forforfor那样好看太多了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(X_train,training=True,X_means=None,X_std=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> training:</span><br><span class="line">        X_means = np.mean(X_train,axis=<span class="number">0</span>)</span><br><span class="line">        X_std = np.std(X_train,axis=<span class="number">0</span>)</span><br><span class="line">    X_train = (X_train - X_means) / X_std</span><br><span class="line">    <span class="keyword">return</span> X_train,X_means,X_std</span><br><span class="line"></span><br><span class="line">X_train, X_mean, X_std = normalize(X_train)</span><br></pre></td></tr></table></figure>
<h3 id="梯度下降"><a class="markdownIt-Anchor" href="#梯度下降"></a> 梯度下降</h3>
<p>定义基本参数，按照之前计算的公式：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>←</mo><msub><mi>w</mi><mi>i</mi></msub><mo>−</mo><mfrac><mi>η</mi><msqrt><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msqrt></mfrac><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>−</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>b</mi><mo>←</mo><mi>b</mi><mo>−</mo><mfrac><mi>η</mi><msqrt><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msqrt></mfrac><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>−</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w_i \leftarrow w_i - \frac{\eta}{\sqrt{t+1}}(y^*- \sigma(w_ix_i+b))x_i, b \leftarrow b - \frac{\eta}{\sqrt{t+1}}(y^* - \sigma(w_ix_i+b))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.03756em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.244445em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8655550000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-2.825555em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17444499999999996em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">b</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.03756em;vertical-align:-0.93em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.244445em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8655550000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-2.825555em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17444499999999996em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">w = np.zeros(data_dim)</span><br><span class="line">b = np.zeros(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">iteration_num = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">step = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.clip(<span class="number">1.0</span>/(<span class="number">1.0</span> + np.exp(-z)), <span class="number">1e-8</span>, <span class="number">1</span> - <span class="number">1e-8</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(X,w,b)</span>:</span></span><br><span class="line">    temp = np.matmul(X,w)</span><br><span class="line">    <span class="keyword">return</span> sigmoid(temp + b)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span><span class="params">(X,w,b,Y_label)</span>:</span></span><br><span class="line">    y_pred = f(X,w,b)</span><br><span class="line">    pred_error = Y_label - y_pred</span><br><span class="line">    w_grad = -np.sum(pred_error * X.T,axis=<span class="number">1</span>)</span><br><span class="line">    b_grad = -np.sum(pred_error)</span><br><span class="line">    <span class="keyword">return</span> w_grad, b_grad</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> range(int(np.floor(train_size/batch_size))):</span><br><span class="line">    X = X_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line">    Y = Y_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line"></span><br><span class="line">    y_pred = f(X,w,b)</span><br><span class="line">    w_grad, b_grad = gradient(X,w,b,Y)</span><br><span class="line"></span><br><span class="line">    w = w - learning_rate / np.sqrt(step) * w_grad</span><br><span class="line">    b = b - learning_rate / np.sqrt(step) * b_grad</span><br></pre></td></tr></table></figure>
<h3 id="计算准确率"><a class="markdownIt-Anchor" href="#计算准确率"></a> 计算准确率</h3>
<p>每跑完整个数据集一次，都需要做一次准确度的测试，不然都不知道做的准不准确。这里用sigmoid的结果与真实结果之差的均值作为误差，也就是分类错误百分比，以及loss function用到的交叉熵作为衡量基准。这些数据只是用于生成图，由人来判断自己的程序有没有问题而已。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_loss</span><span class="params">(y_pred,Y_label)</span>:</span></span><br><span class="line">    cross_entropy = -np.dot(Y_label,np.log(y_pred)) - np.dot(<span class="number">1</span>-Y_label,np.log(<span class="number">1</span>-y_pred))</span><br><span class="line">    <span class="keyword">return</span> cross_entropy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(y_pred,Y_label)</span>:</span></span><br><span class="line">    acc = <span class="number">1</span> - np.mean(np.abs(y_pred-Y_label))</span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br><span class="line">Y_train_pred = np.round(f(X_train,w,b))</span><br><span class="line">train_acc = accuracy(Y_train_pred,Y_train)</span><br><span class="line">train_loss = cross_entropy_loss(Y_train_pred,Y_train)</span><br><span class="line"></span><br><span class="line">Y_dev_pred = np.round(f(X_dev,w,b))</span><br><span class="line">dev_acc = accuracy(Y_dev_pred,Y_dev)</span><br><span class="line">dev_loss = cross_entropy_loss(Y_dev_pred,Y_dev)</span><br></pre></td></tr></table></figure>
<h3 id="随机顺序梯度下降"><a class="markdownIt-Anchor" href="#随机顺序梯度下降"></a> 随机顺序梯度下降</h3>
<p>如果每次都按照相同的顺序梯度下降，可能会造成某种程度上的过拟合，这个是与序列顺序相关的。因此，在每次迭代时，可以先把序列随机化就可以避免掉这种过拟合。最后在console打印最终的拟合程度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(iteration_num):</span><br><span class="line">    shuffle(X_train, Y_train)</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(int(np.floor(train_size/batch_size))):</span><br><span class="line">        X = X_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line">        Y = Y_train[idx*batch_size:(idx+<span class="number">1</span>)*batch_size]</span><br><span class="line"></span><br><span class="line">        y_pred = f(X,w,b)</span><br><span class="line">        w_grad, b_grad = gradient(X,w,b,Y)</span><br><span class="line"></span><br><span class="line">        w = w - learning_rate / np.sqrt(step) * w_grad</span><br><span class="line">        b = b - learning_rate / np.sqrt(step) * b_grad</span><br><span class="line"></span><br><span class="line">    Y_train_pred = np.round(f(X_train,w,b))</span><br><span class="line">    train_acc = accuracy(Y_train_pred,Y_train)</span><br><span class="line">    train_loss = cross_entropy_loss(Y_train_pred,Y_train)</span><br><span class="line">    train_acc_his.append(train_acc)</span><br><span class="line">    train_loss_his.append(train_loss)</span><br><span class="line"></span><br><span class="line">    Y_dev_pred = np.round(f(X_dev,w,b))</span><br><span class="line">    dev_acc = accuracy(Y_dev_pred,Y_dev)</span><br><span class="line">    dev_loss = cross_entropy_loss(Y_dev_pred,Y_dev)</span><br><span class="line">    dev_acc_his.append(dev_acc)</span><br><span class="line">    dev_loss_his.append(dev_loss)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Training loss: &#123;&#125;'</span>.format(train_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Development loss: &#123;&#125;'</span>.format(dev_loss[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Training accuracy: &#123;&#125;'</span>.format(train_acc[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">'Development accuracy: &#123;&#125;'</span>.format(dev_acc[<span class="number">-1</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="打印图表显示"><a class="markdownIt-Anchor" href="#打印图表显示"></a> 打印图表显示</h3>
<p>以前居然还没用过这种debug方法，这次学到了，看来以后在别的地方也可以这样试试。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/07/16/2020-07-16-classification-hw2/" data-id="ckcyxa201009stctmlaiordlx" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/07/17/2020-07-17-cnn/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          CNN实验
        
      </div>
    </a>
  
  
    <a href="/2020/07/15/2020-07-15-classification-base/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">分类问题作业-课程内容整理</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/刷题记录/">刷题记录</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/区块链/">区块链</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/密码学/">密码学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/根域名/">根域名</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DHT/">DHT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DNS/">DNS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/acm/">acm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/android/">android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/arch/">arch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blockstack/">blockstack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/codeforces/">codeforces</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ctf/">ctf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fabric/">fabric</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/">go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/namecoin/">namecoin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node-js/">node.js</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ssh/">ssh</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zookeeper/">zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/以太坊/">以太坊</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/刷题/">刷题</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/区块链/">区块链</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/实验/">实验</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/密码学/">密码学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数学/">数学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/智能合约/">智能合约</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/根域名/">根域名</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/概率论/">概率论</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/比特币/">比特币</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/源码/">源码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/漏洞/">漏洞</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编程语言/">编程语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/联盟链/">联盟链</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/虚拟机/">虚拟机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/超级账本/">超级账本</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/DHT/" style="font-size: 10px;">DHT</a> <a href="/tags/DNS/" style="font-size: 16px;">DNS</a> <a href="/tags/acm/" style="font-size: 10px;">acm</a> <a href="/tags/android/" style="font-size: 10px;">android</a> <a href="/tags/arch/" style="font-size: 14px;">arch</a> <a href="/tags/blockstack/" style="font-size: 13px;">blockstack</a> <a href="/tags/codeforces/" style="font-size: 10px;">codeforces</a> <a href="/tags/ctf/" style="font-size: 10px;">ctf</a> <a href="/tags/docker/" style="font-size: 12px;">docker</a> <a href="/tags/fabric/" style="font-size: 12px;">fabric</a> <a href="/tags/github/" style="font-size: 12px;">github</a> <a href="/tags/go/" style="font-size: 11px;">go</a> <a href="/tags/leetcode/" style="font-size: 11px;">leetcode</a> <a href="/tags/linux/" style="font-size: 19px;">linux</a> <a href="/tags/namecoin/" style="font-size: 13px;">namecoin</a> <a href="/tags/node-js/" style="font-size: 12px;">node.js</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/ssh/" style="font-size: 11px;">ssh</a> <a href="/tags/zookeeper/" style="font-size: 10px;">zookeeper</a> <a href="/tags/以太坊/" style="font-size: 17px;">以太坊</a> <a href="/tags/刷题/" style="font-size: 13px;">刷题</a> <a href="/tags/区块链/" style="font-size: 20px;">区块链</a> <a href="/tags/大数据/" style="font-size: 11px;">大数据</a> <a href="/tags/实验/" style="font-size: 13px;">实验</a> <a href="/tags/密码学/" style="font-size: 13px;">密码学</a> <a href="/tags/数学/" style="font-size: 13px;">数学</a> <a href="/tags/智能合约/" style="font-size: 12px;">智能合约</a> <a href="/tags/机器学习/" style="font-size: 18px;">机器学习</a> <a href="/tags/根域名/" style="font-size: 15px;">根域名</a> <a href="/tags/概率论/" style="font-size: 11px;">概率论</a> <a href="/tags/比特币/" style="font-size: 12px;">比特币</a> <a href="/tags/深度学习/" style="font-size: 12px;">深度学习</a> <a href="/tags/源码/" style="font-size: 11px;">源码</a> <a href="/tags/漏洞/" style="font-size: 10px;">漏洞</a> <a href="/tags/算法/" style="font-size: 14px;">算法</a> <a href="/tags/编程语言/" style="font-size: 11px;">编程语言</a> <a href="/tags/联盟链/" style="font-size: 13px;">联盟链</a> <a href="/tags/虚拟机/" style="font-size: 10px;">虚拟机</a> <a href="/tags/超级账本/" style="font-size: 11px;">超级账本</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/07/23/2020-07-23-git-multi-accounts/">git多账号管理</a>
          </li>
        
          <li>
            <a href="/2020/07/23/2020-07-23-rnn-lstm/">RNN-lstm介绍</a>
          </li>
        
          <li>
            <a href="/2020/07/22/2020-07-22-semi-supervise/">半监督学习</a>
          </li>
        
          <li>
            <a href="/2020/07/21/2020-07-21-deep-learning-base/">深度学习基础</a>
          </li>
        
          <li>
            <a href="/2020/07/17/2020-07-17-cnn/">CNN实验</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Renne<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>